{
 "metadata": {
  "name": "",
  "signature": "sha256:9c9cd08fb8a7e3bb6c31d2f110a41c3ffbbe0987049f3bd2f280726f3c359bfe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Introducci\u00f3n \n",
      "\n",
      "\"\"\"Este proyecto se trata de un trabajo de corpus sobre las diferencias ling\u00fc\u00edsticas entre hablantes de herencia, hablantes \n",
      "nativos y hablantes de segunda lengua\"\"\"\n",
      "\n",
      "\n",
      "## Adquisici\u00f3n de los dados para los hablantes nativos\n",
      "import requests\n",
      "import zipfile\n",
      "import StringIO\n",
      "\n",
      "zip_file_url = 'http://lenguajeacademico.info/proyecto/corpus_CLAE.zip'\n",
      "r = requests.get(zip_file_url)\n",
      "z = zipfile.ZipFile(StringIO.StringIO(r.content))\n",
      "z.extractall()\n",
      "\n",
      "%cd corpus_CLAE/\n",
      "%rm C*.txt\n",
      "%ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/christopherstewart/Desktop/sp_heritage/1.1/corpus_CLAE\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MGEn1.txt     MGRm19.txt    MHPr12.txt    MHRm4.txt     MLtEn7.txt\r\n",
        "MGEn10.txt    MGRm2.txt     MHPr13.txt    MHRm5.txt     MLtEn8.txt\r\n",
        "MGEn11.txt    MGRm20.txt    MHPr14.txt    MHRm6.txt     MLtEn9.txt\r\n",
        "MGEn12.txt    MGRm3.txt     MHPr2.txt     MHRm7.txt     MLtPr1.txt\r\n",
        "MGEn13.txt    MGRm4.txt     MHPr3.txt     MHRm8.txt     MLtPr10.txt\r\n",
        "MGEn14.txt    MGRm5.txt     MHPr4.txt     MHRm9.txt     MLtPr11.txt\r\n",
        "MGEn15.txt    MGRm6.txt     MHPr5.txt     MLtEn1.txt    MLtPr12.txt\r\n",
        "MGEn16.txt    MGRm7.txt     MHPr6.txt     MLtEn10.txt   MLtPr13.txt\r\n",
        "MGEn17.txt    MGRm8.txt     MHPr7.txt     MLtEn11.txt   MLtPr14.txt\r\n",
        "MGEn18.txt    MGRm9.txt     MHPr8.txt     MLtEn12.txt   MLtPr15.txt\r\n",
        "MGEn19.txt    MGRp1.txt     MHPr9.txt     MLtEn13.txt   MLtPr2.txt\r\n",
        "MGEn2.txt     MGRp2.txt     MHRm1.txt     MLtEn14.txt   MLtPr3.txt\r\n",
        "MGEn20.txt    MGRp3.txt     MHRm11.txt    MLtEn15.txt   MLtPr4.txt\r\n",
        "MGEn3.txt     MGRp4.txt     MHRm12.txt    MLtEn16.txt   MLtPr5.txt\r\n",
        "MGEn4.txt     MGRp5.txt     MHRm13.txt    MLtEn17.txt   MLtPr6.txt\r\n",
        "MGEn5.txt     MGRp6.txt     MHRm14.txt    MLtEn18.txt   MLtPr7.txt\r\n",
        "MGEn6.txt     MGRp8.txt     MHRm15.txt    MLtEn19.txt   MLtPr8.txt\r\n",
        "MGEn8.txt     MGRp9.txt     MHRm17.txt    MLtEn2.txt    MLtPr9.txt\r\n",
        "MGEn9.txt     MHEn1.txt     MHRm18.txt    MLtEn20.txt   MLtRes1.txt\r\n",
        "MGRm1.txt     MHEn11.txt    MHRm19.txt    MLtEn21.txt   MLtRes10.txt\r\n",
        "MGRm10.txt    MHEn12.txt    MHRm2.txt     MLtEn22.txt   MLtRes11.txt\r\n",
        "MGRm11.txt    MHEn3.txt     MHRm20.txt    MLtEn23.txt   MLtRes2.txt\r\n",
        "MGRm12.txt    MHEn5.txt     MHRm21.txt    MLtEn24.txt   MLtRes3.txt\r\n",
        "MGRm13.txt    MHEn7.txt     MHRm22.txt    MLtEn25.txt   MLtRes4.txt\r\n",
        "MGRm14.txt    MHEn8.txt     MHRm23.txt    MLtEn26.txt   MLtRes5.txt\r\n",
        "MGRm15.txt    MHEn9.txt     MHRm24.txt    MLtEn3.txt    MLtRes6.txt\r\n",
        "MGRm16.txt    MHPr1.txt     MHRm25.txt    MLtEn4.txt    MLtRes7.txt\r\n",
        "MGRm17.txt    MHPr10.txt    MHRm26.txt    MLtEn5.txt    MLtRes8.txt\r\n",
        "MGRm18.txt    MHPr11.txt    MHRm3.txt     MLtEn6.txt    MLtRes9.txt\r\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Contrucci\u00f3n del corpus (tokenization)\n",
      "\n",
      "import nltk\n",
      "from nltk.corpus import PlaintextCorpusReader\n",
      "from nltk import FreqDist\n",
      "\n",
      "path = '/Users/christopherstewart/Desktop/sp_heritage/1.1/corpus_CLAE'\n",
      "corp = Text(PlaintextCorpusReader(path, '.*', encoding='utf8').words())\n",
      "freqs = FreqDist(corp)\n",
      "freqs.tabulate(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  de    ,   la    .  que    y   en   el    a  los \n",
        "17622 14685 11170 9186 8283 7574 6376 6295 4936 4782 \n"
       ]
      }
     ],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Eliminaci\u00f3n de la puntuacion\n",
      "import string\n",
      "\n",
      "corp_clean = [w for w in corp if w.isalpha() ]\n",
      "freqs_0 = FreqDist(corp_clean)\n",
      "freqs_0.tabulate(25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  de   la  que    y   en   el    a  los   se  las  del   es  por  una   un  con   no como para   su   lo   al    o   La  m\u00e1s \n",
        "17622 11170 8283 7574 6376 6295 4936 4782 3502 3387 3199 2587 2445 2427 2276 1898 1762 1762 1740 1526 1447 1233 1142 1082  996 \n"
       ]
      }
     ],
     "prompt_number": 464
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Homogeneizaci\u00f3n de clase de caracteres\n",
      "\n",
      "corp_clean2 = [token.lower() for token in corp_clean]\n",
      "freqs_1 = FreqDist(corp_clean2)\n",
      "freqs_1.tabulate(24)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  de   la  que    y   el   en  los    a   se  las  del   es  por  una   un  con para   no como   su   lo   al    o  m\u00e1s \n",
        "17965 12392 8313 7765 7301 7087 5289 5143 3694 3637 3263 2805 2626 2514 2351 1992 1925 1872 1859 1579 1520 1321 1162 1004 \n"
       ]
      }
     ],
     "prompt_number": 467
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Eliminaci\u00f3n de las palabras m\u00e1s comunes (para ver el contenido)\n",
      "from nltk.corpus import stopwords\n",
      "\n",
      "stopset = set(stopwords.words('spanish'))\n",
      "corp_clean3 = [w for w in corp_clean2 if not w in stopset]\n",
      "freqs_2 = FreqDist(corp_clean3)\n",
      "freqs_2.tabulate(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "geograf\u00eda  ser suelo historia quijote  as\u00ed parte  don puede pa\u00edses desarrollo   si vida cada tiempo \n",
        " 970  603  589  576  532  428  425  418  410  407  401  385  352  348  299 \n"
       ]
      }
     ],
     "prompt_number": 463
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Aislar las colocaciones\n",
      "from nltk.collocations import BigramCollocationFinder\n",
      "from nltk.metrics import BigramAssocMeasures\n",
      "\n",
      "corp2 = Text(PlaintextCorpusReader(path, '.*', encoding='utf8').words())\n",
      "toks2_1 = [w.lower for w in corp2]\n",
      "bigram_colls = BigramCollocationFinder.from_words(toks2_1)\n",
      "filter_stops = lambda w: w in stopset\n",
      "bigram_colls.apply_word_filter(filter_stops)\n",
      "bigram_colls.nbest(BigramAssocMeasures.likelihood_ratio, 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}