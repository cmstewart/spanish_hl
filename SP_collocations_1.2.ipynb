{
 "metadata": {
  "name": "",
  "signature": "sha256:9f46fd26240ca77f7e6ce9a3334b0fa4affb8e97f2c1790399a41b7de8c6d635"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Introducci\u00f3n \n",
      "\n",
      "\"\"\"Este proyecto se trata de un trabajo de corpus sobre las diferencias ling\u00fc\u00edsticas entre hablantes nativos y hablantes de segunda lengua (y luego de herencia...)\"\"\"\n",
      "\n",
      "\n",
      "## Adquisici\u00f3n de los dados \n",
      "import requests\n",
      "import zipfile\n",
      "import StringIO\n",
      "\n",
      "zip_file_url = 'http://lenguajeacademico.info/proyecto/corpus_CLAE.zip'\n",
      "r = requests.get(zip_file_url)\n",
      "z = zipfile.ZipFile(StringIO.StringIO(r.content))\n",
      "z.extractall()\n",
      "\n",
      "%cd corpus_CLAE/\n",
      "%rm CLgMg1.txt\n",
      "%mkdir L1\n",
      "%mv M*.txt ./L1\n",
      "%mkdir L2\n",
      "%mv C*.txt ./L2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/christopherstewart/Desktop/sp_heritage/3/3.1/corpus_CLAE/corpus_CLAE\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Demonstraci\u00f3n de las 20 palabras m\u00e1s usadas por los hablantes nativos.\n",
      "\n",
      "import nltk\n",
      "from nltk.corpus import PlaintextCorpusReader, stopwords\n",
      "from nltk import Text\n",
      "from nltk import FreqDist\n",
      "\n",
      "L1_path = '/Users/christopherstewart/Desktop/sp_heritage/3/3.1/corpus_CLAE/corpus_CLAE/L1'\n",
      "L1_corp = [w.lower() for w in Text(PlaintextCorpusReader(L1_path, '.*', encoding='utf-8').words()) if w.isalpha()]\n",
      "L1_toks_fd = FreqDist(L1_corp)\n",
      "L1_toks_fd.tabulate(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  de   la  que    y   el   en  los    a   se  las  del   es  por  una   un  con para   no como   su \n",
        "17965 12392 8313 7765 7301 7087 5289 5143 3694 3637 3263 2805 2626 2514 2351 1992 1925 1872 1859 1579 \n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Lo mismo, ahora sin las palabras comunes\n",
      "\n",
      "stopset = set(stopwords.words('spanish'))\n",
      "L1_corp_st = [w for w in L1_corp if w not in stopset]\n",
      "L1_toks_fd_2 = FreqDist(L1_corp_st)\n",
      "L1_toks_fd_2.tabulate(10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "geograf\u00eda  ser suelo historia quijote  as\u00ed parte  don puede pa\u00edses \n",
        " 970  603  589  576  532  428  425  418  410  407 \n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 pares de palabras m\u00e1s comunes en el corpus L1.\n",
      "\n",
      "from nltk.util import bigrams\n",
      "\n",
      "L1_bigrs = FreqDist(bigrams(L1_corp))\n",
      "L1_bigrs.most_common(10)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 101,
       "text": [
        "[((u'de', u'la'), 3222),\n",
        " ((u'de', u'los'), 1562),\n",
        " ((u'en', u'el'), 1178),\n",
        " ((u'de', u'las'), 1072),\n",
        " ((u'en', u'la'), 1044),\n",
        " ((u'a', u'la'), 990),\n",
        " ((u'que', u'se'), 770),\n",
        " ((u'la', u'geograf\\xeda'), 711),\n",
        " ((u'lo', u'que'), 555),\n",
        " ((u'y', u'la'), 544)]"
       ]
      }
     ],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'trigrams' m\u00e1s comunes en el corpus L1.\n",
      "\n",
      "from nltk.util import trigrams\n",
      "\n",
      "L1_trigrs = FreqDist(trigrams(L1_corp))\n",
      "L1_trigrs.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "[((u'de', u'la', u'geograf\\xeda'), 352),\n",
        " ((u'de', u'la', u'historia'), 154),\n",
        " ((u'a', u'trav\\xe9s', u'de'), 119),\n",
        " ((u'a', u'partir', u'de'), 102),\n",
        " ((u'una', u'de', u'las'), 91),\n",
        " ((u'el', u'desarrollo', u'de'), 89),\n",
        " ((u'por', u'lo', u'que'), 78),\n",
        " ((u'una', u'serie', u'de'), 76),\n",
        " ((u'uno', u'de', u'los'), 75),\n",
        " ((u'esperanza', u'de', u'vida'), 75)]"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'tetragrams' m\u00e1s comunes en el corpus L1.\n",
      "\n",
      "from nltk.util import ngrams\n",
      "\n",
      "def make_ngrams(input_list, n):\n",
      "  return zip(*[input_list[i:] for i in range(n)])\n",
      "\n",
      "L1_tetra = FreqDist(make_ngrams(L1_corp, 4))\n",
      "L1_tetra.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "[((u'la', u'mayor\\xeda', u'de', u'los'), 48),\n",
        " ((u'\\xedndice', u'de', u'desarrollo', u'humano'), 46),\n",
        " ((u'a', u'lo', u'largo', u'de'), 46),\n",
        " ((u'la', u'esperanza', u'de', u'vida'), 41),\n",
        " ((u'de', u'las', u'naciones', u'unidas'), 40),\n",
        " ((u'de', u'tal', u'forma', u'que'), 36),\n",
        " ((u'teor\\xeda', u'de', u'la', u'geograf\\xeda'), 36),\n",
        " ((u'don', u'quijote', u'de', u'la'), 35),\n",
        " ((u'en', u'el', u'caso', u'de'), 34),\n",
        " ((u'de', u'vida', u'al', u'nacer'), 33)]"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'pentagrams' m\u00e1s comunes en el corpus L1.\n",
      "\n",
      "L1_penta = FreqDist(make_ngrams(L1_corp, 5))\n",
      "L1_penta.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "[((u'esperanza', u'de', u'vida', u'al', u'nacer'), 32),\n",
        " ((u'don', u'quijote', u'de', u'la', u'mancha'), 29),\n",
        " ((u'los', u'derechos', u'de', u'los', u'trabajadores'), 28),\n",
        " ((u'tasa', u'bruta', u'combinada', u'de', u'matriculaci\\xf3n'), 27),\n",
        " ((u'a', u'lo', u'largo', u'de', u'la'), 26),\n",
        " ((u'la', u'teor\\xeda', u'de', u'la', u'geograf\\xeda'), 26),\n",
        " ((u'ense\\xf1anza', u'primaria', u'secundaria', u'y', u'terciaria'), 25),\n",
        " ((u'tasa', u'de', u'alfabetizaci\\xf3n', u'de', u'adultos'), 23),\n",
        " ((u'el', u'\\xedndice', u'de', u'desarrollo', u'humano'), 23),\n",
        " ((u'en', u'ense\\xf1anza', u'primaria', u'secundaria', u'y'), 22)]"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'sextagrams' m\u00e1s comunes en el corpus L1.\n",
      "\n",
      "L1_sexta = FreqDist(make_ngrams(L1_corp, 6))\n",
      "L1_sexta.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "[((u'en', u'ense\\xf1anza', u'primaria', u'secundaria', u'y', u'terciaria'),\n",
        "  22),\n",
        " ((u'de',\n",
        "   u'matriculaci\\xf3n',\n",
        "   u'en',\n",
        "   u'ense\\xf1anza',\n",
        "   u'primaria',\n",
        "   u'secundaria'),\n",
        "  21),\n",
        " ((u'tasa', u'bruta', u'combinada', u'de', u'matriculaci\\xf3n', u'en'), 21),\n",
        " ((u'matriculaci\\xf3n',\n",
        "   u'en',\n",
        "   u'ense\\xf1anza',\n",
        "   u'primaria',\n",
        "   u'secundaria',\n",
        "   u'y'),\n",
        "  21),\n",
        " ((u'bruta', u'combinada', u'de', u'matriculaci\\xf3n', u'en', u'ense\\xf1anza'),\n",
        "  20),\n",
        " ((u'combinada',\n",
        "   u'de',\n",
        "   u'matriculaci\\xf3n',\n",
        "   u'en',\n",
        "   u'ense\\xf1anza',\n",
        "   u'primaria'),\n",
        "  20),\n",
        " ((u'perspectivas', u'de', u'poblaci\\xf3n', u'en', u'el', u'mundo'), 18),\n",
        " ((u'de', u'las', u'perspectivas', u'de', u'poblaci\\xf3n', u'en'), 18),\n",
        " ((u'la', u'esperanza', u'de', u'vida', u'al', u'nacer'), 18),\n",
        " ((u'las', u'perspectivas', u'de', u'poblaci\\xf3n', u'en', u'el'), 18)]"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Demonstraci\u00f3n de las 20 palabras m\u00e1s usadas por los hablantes de segunda lengua.\n",
      "\n",
      "L2_path = '/Users/christopherstewart/Desktop/sp_heritage/3/3.1/corpus_CLAE/corpus_CLAE/L2'\n",
      "L2_corp = [w.lower() for w in PlaintextCorpusReader(L2_path, '.*', encoding='utf-8').words()]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "UnicodeDecodeError",
       "evalue": "'utf8' codec can't decode byte 0xfe in position 0: invalid start byte",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-120-be66870fdb4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mL2_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/christopherstewart/Desktop/sp_heritage/3/3.1/corpus_CLAE/corpus_CLAE/L2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mL2_corp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPlaintextCorpusReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL2_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nltk/corpus/reader/util.pyc\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# Get everything we can from this piece.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_tok\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nltk/corpus/reader/util.pyc\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_toknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoknum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_blocknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             assert isinstance(tokens, (tuple, list, AbstractLazySequence)), (\n\u001b[1;32m    293\u001b[0m                 \u001b[0;34m'block reader %s() should return list or tuple.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nltk/corpus/reader/plaintext.pyc\u001b[0m in \u001b[0;36m_read_word_block\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Read 20 lines at a time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0mstartpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbytebuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0mnew_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;31m# If we're at a '\\r', then read one extra character, since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m         \u001b[0;31m# Decode the bytes into unicode characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_decoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_incr_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \u001b[0;31m# If we got bytes but couldn't decode any, then read further.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nltk/data.pyc\u001b[0m in \u001b[0;36m_incr_decode\u001b[0;34m(self, bytes)\u001b[0m\n\u001b[1;32m   1357\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m                 \u001b[0;31m# If the exception occurs at the end of the string,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/encodings/utf_8.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf8' codec can't decode byte 0xfe in position 0: invalid start byte"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 pares de palabras m\u00e1s comunes en el corpus L2.\n",
      "\n",
      "from nltk.util import bigrams\n",
      "\n",
      "L2_bigrs = FreqDist(bigrams(L2_corp))\n",
      "L2_bigrs.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "[((u'\\x00', u'\\x00'), 166157),\n",
        " ((u'\\x00', u'e'), 109812),\n",
        " ((u'e', u'\\x00'), 107990),\n",
        " ((u'\\x00', u'a'), 99600),\n",
        " ((u'a', u'\\x00'), 95383),\n",
        " ((u'\\x00', u'o'), 70129),\n",
        " ((u'o', u'\\x00'), 66094),\n",
        " ((u'\\x00', u's'), 61636),\n",
        " ((u'\\x00', u'n'), 60744),\n",
        " ((u'n', u'\\x00'), 59645)]"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}