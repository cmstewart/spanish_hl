toks = corp_2.words()
bigrs = BigramCollocationFinder.from_words(toks)
type(bigrs)



bcf = BigramCollocationFinder.from_words(words)

stopset = set(stopwords.words('spanish'))
filter_stops = lambda w: len(w) < 3 or w in stopset


toks = [w.lower for w in corp_2.words()]
bigrs = BigramCollocationFinder.from_words(toks)

from nltk.corpus import stopwords

stopset = set(stopwords.words('spanish'))

corp_clean = [w for w in corp if w.isalpha() ]



toks2 = corp2.words()
bigrs_2 = FreqDist(bigrams(toks2))
trigrs_2 = FreqDist(trigrams(toks2))
bigrs_2.tabulate(10)
trigrs_2.tabulate(10)


def tabulate(self, *args, **kwargs):
        """
        Tabulate the given samples from the frequency distribution (cumulative),
        displaying the most frequent sample first.  If an integer
        parameter is supplied, stop after this many samples have been
        plotted.

        :param samples: The samples to plot (default is all samples)
        :type samples: list
        """
        if len(args) == 0:
            args = [len(self)]
        samples = [item for item, _ in self.most_common(*args)]

        cumulative = _get_kwarg(kwargs, 'cumulative', False)
        if cumulative:
            freqs = list(self._cumulative_frequencies(samples))
        else:
            freqs = [self[sample] for sample in samples]
        # percents = [f * 100 for f in freqs]  only in ProbDist?

        for i in range(len(samples)):
            print("%4s %4s" % samples[i])
        print()
        for i in range(len(samples)):
            print("%4d" % freqs[i])
        print()
        


### STILL NEED TO TAKE OUT PUNCTUATION
from nltk.util import ngrams

bigrams_2 = FreqDist(bigrams([w.lower() for w in corp2.words() if w.isalpha()]))





trigrs_2 = FreqDist(ngrams(toks_2,3))
tetragrs_2 = FreqDist(ngrams(toks_2,4))
pentagrs_2 = FreqDist(ngrams(toks_2,5))
sextagrs_2 = FreqDist(ngrams(toks_2,6))

type(bigrs_2)






wordlists = PlaintextCorpusReader(corpus_root, '.*', encoding='utf-8')

words = wordlists.words()
fdist = FreqDist(words)
	
%pwd


raw = corp.raw().encode('utf-8', 'ignore').lower()



from __future__ import division
import nltk, re, pprint
from nltk.corpus import PlaintextCorpusReader
from nltk.text import Text
from nltk import FreqDist
from nltk.tokenize import RegexpTokenizer

path = '/Users/christopherstewart/Desktop/sp_heritage/1.1/corpus_CLAE'
corp = PlaintextCorpusReader(path, '.*', encoding='utf8')
raw = corp.raw().encode('utf-8', 'ignore').lower()
tokenizer = RegexpTokenizer(r'\w+')
toks = tokenizer.tokenize(raw)
freqs = FreqDist(toks)
freqs.tabulate(30)
len(freqs)


from nltk.corpus import stopwords

stopset = set(stopwords.words('spanish'))
tokens = [w for w in toks if not w in stopset]
fdist2 = FreqDist(tokens)
fdist2.tabulate(20)


def make_ngrams(input_list, n):
  return zip(*[input_list[i:] for i in range(n)])

tetra = make_ngrams(corp_clean2, 4)
penta = make_ngrams(corp_clean2, 5)
sexta = make_ngrams(corp_clean2, 6)
septa = make_ngrams(corp_clean2, 7)