{
 "metadata": {
  "name": "",
  "signature": "sha256:8d228f65c34472b946ef3ca268a696007ea836cc505e1776bc399d3702a69b65"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Introducci\u00f3n \n",
      "\n",
      "\"\"\"Este proyecto se trata de un trabajo de corpus sobre las diferencias ling\u00fc\u00edsticas entre hablantes nativos y hablantes de segunda lengua\"\"\"\n",
      "\n",
      "\n",
      "## Adquisici\u00f3n de los dados para los hablantes nativos\n",
      "\n",
      "import requests\n",
      "import zipfile\n",
      "import StringIO\n",
      "\n",
      "zip_file_url = 'http://lenguajeacademico.info/proyecto/corpus_CLAE.zip'\n",
      "r = requests.get(zip_file_url)\n",
      "z = zipfile.ZipFile(StringIO.StringIO(r.content))\n",
      "z.extractall()\n",
      "\n",
      "%cd corpus_CLAE/\n",
      "%rm C*.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/christopherstewart/Desktop/sp_heritage/5/corpus_CLAE/corpus_CLAE\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Las 20 palabras m\u00e1s usadas por los hablantes nativos.\n",
      "\n",
      "import nltk\n",
      "from nltk.corpus import PlaintextCorpusReader\n",
      "from nltk import Text\n",
      "from nltk import FreqDist\n",
      "\n",
      "L1_path = '.'\n",
      "L1_corp = [w.lower() for w in Text(PlaintextCorpusReader(L1_path, '.*', encoding='utf-8').words()) if w.isalpha()]\n",
      "L1_toks_fd = FreqDist(L1_corp)\n",
      "L1_toks_fd.tabulate(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  de   la  que    y   el   en  los    a   se  las  del   es  por  una   un   no para  con como   su \n",
        "20619 13792 10467 8939 8468 8452 6753 6377 4183 4057 3480 3426 3189 3024 2897 2543 2493 2323 2210 1841 \n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Las 20 palabras m\u00e1s usadas por los hablantes L2 (del corpus de Maria [email del 25 de mayo])\n",
      "\n",
      "L2_path = '.'\n",
      "L2_corp = [w.lower() for w in Text(PlaintextCorpusReader(L2_path, 'CORPUS_TOTAL.txt', encoding='utf-8').words()) if w.isalpha()]\n",
      "L2_toks_fd = FreqDist(L2_corp)\n",
      "L2_toks_fd.tabulate(20)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  de  que  los   la   en    a    y   el   no   es para  por   un  una   se  las inmigrantes como  con unidos \n",
        "2654 2154 1464 1400 1365 1234 1174 1167  671  621  568  563  546  510  489  420  398  351  331  288 \n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 pares de palabras m\u00e1s usados en el corpus L1.\n",
      "\n",
      "from nltk.util import bigrams\n",
      "\n",
      "L1_bigrs = FreqDist(bigrams(L1_corp))\n",
      "L1_bigrs.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[((u'de', u'la'), 3407),\n",
        " ((u'de', u'los'), 1806),\n",
        " ((u'en', u'el'), 1354),\n",
        " ((u'en', u'la'), 1154),\n",
        " ((u'a', u'la'), 1147),\n",
        " ((u'de', u'las'), 1129),\n",
        " ((u'que', u'se'), 898),\n",
        " ((u'la', u'geograf\\xeda'), 712),\n",
        " ((u'a', u'los'), 645),\n",
        " ((u'lo', u'que'), 626)]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 pares de palabras m\u00e1s usados en el corpus L2.\n",
      "\n",
      "L2_bigrs = FreqDist(bigrams(L2_corp))\n",
      "L2_bigrs.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[((u'estados', u'unidos'), 253),\n",
        " ((u'de', u'los'), 244),\n",
        " ((u'los', u'inmigrantes'), 236),\n",
        " ((u'a', u'los'), 221),\n",
        " ((u'de', u'la'), 185),\n",
        " ((u'los', u'estados'), 178),\n",
        " ((u'que', u'los'), 176),\n",
        " ((u'en', u'el'), 176),\n",
        " ((u'a', u'la'), 157),\n",
        " ((u'en', u'los'), 153)]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'trigrams' m\u00e1s usados en el corpus L1.\n",
      "\n",
      "from nltk.util import trigrams\n",
      "\n",
      "L1_trigrs = FreqDist(trigrams(L1_corp))\n",
      "L1_trigrs.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "[((u'de', u'la', u'geograf\\xeda'), 352),\n",
        " ((u'los', u'estados', u'unidos'), 181),\n",
        " ((u'de', u'la', u'historia'), 156),\n",
        " ((u'a', u'trav\\xe9s', u'de'), 123),\n",
        " ((u'a', u'partir', u'de'), 103),\n",
        " ((u'de', u'acuerdo', u'con'), 100),\n",
        " ((u'una', u'de', u'las'), 99),\n",
        " ((u'el', u'desarrollo', u'de'), 91),\n",
        " ((u'uno', u'de', u'los'), 91),\n",
        " ((u'la', u'mayor\\xeda', u'de'), 90)]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'trigrams' m\u00e1s usados en el corpus L2.\n",
      "\n",
      "L2_trigrs = FreqDist(trigrams(L2_corp))\n",
      "L2_trigrs.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "[((u'los', u'estados', u'unidos'), 176),\n",
        " ((u'en', u'los', u'estados'), 80),\n",
        " ((u'que', u'los', u'inmigrantes'), 68),\n",
        " ((u'en', u'este', u'pa\\xeds'), 56),\n",
        " ((u'las', u'personas', u'que'), 47),\n",
        " ((u'a', u'los', u'estudiantes'), 47),\n",
        " ((u'los', u'ee', u'uu'), 46),\n",
        " ((u'de', u'los', u'estados'), 40),\n",
        " ((u'de', u'los', u'inmigrantes'), 36),\n",
        " ((u'una', u'reforma', u'migratoria'), 33)]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'tetragrams' m\u00e1s usados en el corpus L1.\n",
      "\n",
      "from nltk.util import ngrams\n",
      "\n",
      "def make_ngrams(input_list, n):\n",
      "  return zip(*[input_list[i:] for i in range(n)])\n",
      "\n",
      "L1_tetra = FreqDist(make_ngrams(L1_corp, 4))\n",
      "L1_tetra.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[((u'en', u'los', u'estados', u'unidos'), 81),\n",
        " ((u'la', u'mayor\\xeda', u'de', u'los'), 61),\n",
        " ((u'a', u'lo', u'largo', u'de'), 50),\n",
        " ((u'\\xedndice', u'de', u'desarrollo', u'humano'), 46),\n",
        " ((u'de', u'los', u'estados', u'unidos'), 42),\n",
        " ((u'la', u'esperanza', u'de', u'vida'), 41),\n",
        " ((u'de', u'las', u'naciones', u'unidas'), 40),\n",
        " ((u'en', u'el', u'caso', u'de'), 39),\n",
        " ((u'de', u'tal', u'forma', u'que'), 36),\n",
        " ((u'teor\\xeda', u'de', u'la', u'geograf\\xeda'), 36)]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'tetragrams' m\u00e1s usados en el corpus L2.\n",
      "\n",
      "L2_tetra = FreqDist(make_ngrams(L2_corp, 4))\n",
      "L2_tetra.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[((u'en', u'los', u'estados', u'unidos'), 80),\n",
        " ((u'de', u'los', u'estados', u'unidos'), 39),\n",
        " ((u'a', u'los', u'estados', u'unidos'), 32),\n",
        " ((u'en', u'los', u'ee', u'uu'), 24),\n",
        " ((u'mi', u'punto', u'de', u'vista'), 16),\n",
        " ((u'la', u'mayor\\xeda', u'de', u'los'), 13),\n",
        " ((u'estoy', u'de', u'acuerdo', u'con'), 12),\n",
        " ((u'que', u'los', u'inmigrantes', u'no'), 11),\n",
        " ((u'los', u'estados', u'unidos', u'no'), 11),\n",
        " ((u'que', u'las', u'personas', u'que'), 10)]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'pentagrams' m\u00e1s usados en el corpus L1.\n",
      "\n",
      "L1_penta = FreqDist(make_ngrams(L1_corp, 5))\n",
      "L1_penta.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "[((u'esperanza', u'de', u'vida', u'al', u'nacer'), 32),\n",
        " ((u'don', u'quijote', u'de', u'la', u'mancha'), 29),\n",
        " ((u'los', u'derechos', u'de', u'los', u'trabajadores'), 28),\n",
        " ((u'tasa', u'bruta', u'combinada', u'de', u'matriculaci\\xf3n'), 27),\n",
        " ((u'a', u'lo', u'largo', u'de', u'la'), 27),\n",
        " ((u'la', u'teor\\xeda', u'de', u'la', u'geograf\\xeda'), 26),\n",
        " ((u'ense\\xf1anza', u'primaria', u'secundaria', u'y', u'terciaria'), 25),\n",
        " ((u'tasa', u'de', u'alfabetizaci\\xf3n', u'de', u'adultos'), 23),\n",
        " ((u'el', u'\\xedndice', u'de', u'desarrollo', u'humano'), 23),\n",
        " ((u'en', u'ense\\xf1anza', u'primaria', u'secundaria', u'y'), 22)]"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'pentagrams' m\u00e1s usados en el corpus L2.\n",
      "\n",
      "L2_penta = FreqDist(make_ngrams(L2_corp, 5))\n",
      "L2_penta.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[((u'desde', u'mi', u'punto', u'de', u'vista'), 9),\n",
        " ((u'la', u'disciplina', u'en', u'las', u'escuelas'), 9),\n",
        " ((u'congreso', u'de', u'los', u'estados', u'unidos'), 9),\n",
        " ((u'el', u'congreso', u'de', u'los', u'estados'), 9),\n",
        " ((u'en', u'mi', u'punto', u'de', u'vista'), 7),\n",
        " ((u'es', u'el', u'spanglish', u'un', u'idioma'), 7),\n",
        " ((u'diferencias', u'entre', u'lpac', u'y', u'ard'), 6),\n",
        " ((u'los', u'estados', u'unidos', u'los', u'inmigrantes'), 6),\n",
        " ((u'un', u'proyecto', u'de', u'responsabilidad', u'social'), 6),\n",
        " ((u'de', u'los', u'estados', u'unidos', u'y'), 6)]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'sextagrams' m\u00e1s usados en el corpus L1.\n",
      "\n",
      "L1_sexta = FreqDist(make_ngrams(L1_corp, 6))\n",
      "L1_sexta.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[((u'en', u'ense\\xf1anza', u'primaria', u'secundaria', u'y', u'terciaria'),\n",
        "  22),\n",
        " ((u'de',\n",
        "   u'matriculaci\\xf3n',\n",
        "   u'en',\n",
        "   u'ense\\xf1anza',\n",
        "   u'primaria',\n",
        "   u'secundaria'),\n",
        "  21),\n",
        " ((u'tasa', u'bruta', u'combinada', u'de', u'matriculaci\\xf3n', u'en'), 21),\n",
        " ((u'matriculaci\\xf3n',\n",
        "   u'en',\n",
        "   u'ense\\xf1anza',\n",
        "   u'primaria',\n",
        "   u'secundaria',\n",
        "   u'y'),\n",
        "  21),\n",
        " ((u'bruta', u'combinada', u'de', u'matriculaci\\xf3n', u'en', u'ense\\xf1anza'),\n",
        "  20),\n",
        " ((u'combinada',\n",
        "   u'de',\n",
        "   u'matriculaci\\xf3n',\n",
        "   u'en',\n",
        "   u'ense\\xf1anza',\n",
        "   u'primaria'),\n",
        "  20),\n",
        " ((u'perspectivas', u'de', u'poblaci\\xf3n', u'en', u'el', u'mundo'), 18),\n",
        " ((u'de', u'las', u'perspectivas', u'de', u'poblaci\\xf3n', u'en'), 18),\n",
        " ((u'la', u'esperanza', u'de', u'vida', u'al', u'nacer'), 18),\n",
        " ((u'las', u'perspectivas', u'de', u'poblaci\\xf3n', u'en', u'el'), 18)]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Los 10 'sextagrams' m\u00e1s usados en el corpus L2.\n",
      "\n",
      "L2_sexta = FreqDist(make_ngrams(L2_corp, 6))\n",
      "L2_sexta.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[((u'el', u'congreso', u'de', u'los', u'estados', u'unidos'), 9),\n",
        " ((u'formar', u'un', u'grupo', u'con', u'el', u'fin'), 5),\n",
        " ((u'el', u'fin', u'de', u'promover', u'las', u'necesidades'), 5),\n",
        " ((u'grupo', u'con', u'el', u'fin', u'de', u'promover'), 5),\n",
        " ((u'un', u'grupo', u'con', u'el', u'fin', u'de'), 5),\n",
        " ((u'la', u'econom\\xeda', u'de', u'los', u'estados', u'unidos'), 5),\n",
        " ((u'y', u'diferencias', u'entre', u'lpac', u'y', u'ard'), 5),\n",
        " ((u'similitudes', u'y', u'diferencias', u'entre', u'lpac', u'y'), 5),\n",
        " ((u'con', u'el', u'fin', u'de', u'promover', u'las'), 5),\n",
        " ((u'inmigrantes', u'no', u'est\\xe1', u'disminuyendo', u'sino', u'al'), 4)]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}